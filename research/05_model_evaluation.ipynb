{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea55cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Machine-Learning-Project\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a211bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to project root\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca200951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Machine-Learning-Project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba46c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up enviroment using wes package\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/klan86at/End-to-end-Machine-Learning-Project.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"klan86at\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"332b51719afa1eb8c7b19f01b95fd0d1def95031\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31dfb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path: Path\n",
    "    model_path: Path\n",
    "    metric_file_name: Path\n",
    "    all_params: dict\n",
    "    target_column: str\n",
    "    mlflow_uri: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185cefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import*\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae0d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__ (\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "        schema_filepath=SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "\n",
    "        create_directories([self.config.data_validation.root_dir])\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.ElasticNet\n",
    "        #schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_path=config.model_path,\n",
    "            metric_file_name=config.metric_file_name,\n",
    "            all_params=params,\n",
    "            target_column=params.target_column,\n",
    "            mlflow_uri=\"https://dagshub.com/klan86at/End-to-end-Machine-Learning-Project.mlflow\",\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2761daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dagshub.upload import Repo\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from urllib.parse import urlparse\n",
    "from mlProject.utils.common import save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def eval_metrics(self, actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        \"\"\"Windows-proof MLflow/DagsHub logging\"\"\"\n",
    "        \n",
    "        # 1. Load data and model\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        model = joblib.load(self.config.model_path)\n",
    "\n",
    "        # 2. Set tracking URI\n",
    "        tracking_uri = self.config.mlflow_uri or \"file:///mlruns\"\n",
    "        mlflow.set_tracking_uri(tracking_uri.replace('.mlflow', '') + '.mlflow')\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            # 3. Log metrics\n",
    "            X_test = test_data.drop(columns=[self.config.target_column])\n",
    "            y_test = test_data[self.config.target_column]\n",
    "            y_pred = model.predict(X_test)\n",
    "            rmse, mae, r2 = self.eval_metrics(y_test, y_pred)\n",
    "            mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "            # 4. Log parameters\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "\n",
    "            # 5. Save model temporarily\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            temp_path = Path(temp_dir) / f\"model_{time.time_ns()}.joblib\"\n",
    "            joblib.dump(model, temp_path)\n",
    "\n",
    "            # 6. Log model with fallback logic\n",
    "            try:\n",
    "                mlflow.sklearn.log_model(model, \"model\")\n",
    "            except Exception:\n",
    "                if tracking_uri.startswith(\"https://\"): \n",
    "                    from dagshub.upload import Repo\n",
    "                    repo_name = tracking_uri.split('/')[-1].split('.')[0]\n",
    "                    try:\n",
    "                        Repo(\n",
    "                            os.getenv('MLFLOW_TRACKING_USERNAME'),\n",
    "                            repo_name,\n",
    "                            token=os.getenv('MLFLOW_TRACKING_PASSWORD'),\n",
    "                            branch=\"main\"\n",
    "                        ).upload(str(temp_path), \"models/model.joblib\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"DagsHub upload failed: {e}\")\n",
    "                        mlflow.log_artifact(str(temp_path))\n",
    "                else:\n",
    "                    mlflow.log_artifact(str(temp_path))\n",
    "\n",
    "            # 7. Cleanup temp files with retry\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    temp_path.unlink()\n",
    "                    Path(temp_dir).rmdir()\n",
    "                    break\n",
    "                except (PermissionError, FileNotFoundError):\n",
    "                    time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2019878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 17:27:04,436: INFO: common: YAML file config\\config.yaml loaded successfully.]\n",
      "[2025-07-03 17:27:04,442: INFO: common: YAML file params.yaml loaded successfully.]\n",
      "[2025-07-03 17:27:04,449: INFO: common: YAML file schema.yaml loaded successfully.]\n",
      "[2025-07-03 17:27:04,449: INFO: common: Created directory: artifacts/data_validation]\n",
      "[2025-07-03 17:27:04,457: INFO: common: Created directory: artifacts/model_evaluation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 17:27:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 17:27:08,510: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/klan86at/End-to-end-Machine-Learning-Project \"HTTP/1.1 200 OK\"]\n",
      "[2025-07-03 17:27:09,414: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/klan86at/End-to-end-Machine-Learning-Project/branches/main \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading files <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> to <span style=\"color: #008000; text-decoration-color: #008000\">\"klan86at/End-to-end-Machine-Learning-Project\"</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Uploading files \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m to \u001b[32m\"klan86at/End-to-end-Machine-Learning-Project\"\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 17:27:09,674: INFO: helpers: Uploading files (1) to \"klan86at/End-to-end-Machine-Learning-Project\"...]\n",
      "[2025-07-03 17:27:11,478: INFO: _client: HTTP Request: PUT https://dagshub.com/api/v1/repos/klan86at/End-to-end-Machine-Learning-Project/content/main/ \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Upload finished successfully!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Upload finished successfully!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-03 17:27:11,494: INFO: helpers: Upload finished successfully!]\n",
      "üèÉ View run grandiose-bee-780 at: https://dagshub.com/klan86at/End-to-end-Machine-Learning-Project.mlflow/#/experiments/0/runs/7a470895b3304783911a693c7c38c39e\n",
      "üß™ View experiment at: https://dagshub.com/klan86at/End-to-end-Machine-Learning-Project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation pipeline\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation_config = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_evaluation_config.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa83587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
